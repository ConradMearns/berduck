{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pytextrank\n",
    "import pandas as pd\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "nlp = spacy.load('en_core_web_md') \n",
    "\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob \n",
    "spacy_text_blob = SpacyTextBlob() \n",
    "nlp.add_pipe(spacy_text_blob) \n",
    "\n",
    "tr = pytextrank.TextRank()\n",
    "nlp.add_pipe(tr.PipelineComponent, name=\"textrank\", last=True)\n",
    "\n",
    "# from sense2vec import Sense2VecComponent\n",
    "# s2v = Sense2VecComponent(nlp.vocab).from_disk(\"/home/maze/Hacking/_datasets/s2v_old\")\n",
    "# nlp.add_pipe(s2v)\n",
    "\n",
    "df = pd.read_csv('emoji-faces.csv')\n",
    "# emoji_list = list(df[\"Char\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datetime import date, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_spacy_doc(text):\n",
    "    doc = nlp(text)\n",
    "    return(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For generating emoji through a simple sentiment-analysis grid\n",
    "def sympathize(doc): \n",
    "    neutrality = 1 - doc._.sentiment.subjectivity\n",
    "    return(doc._.sentiment.polarity, neutrality)\n",
    "\n",
    "def dist(coord, loc):\n",
    "    a = abs(coord[0]-loc[0])\n",
    "    b = abs(coord[1]-loc[1])\n",
    "    c = sqrt(a**2 + b**2)\n",
    "    return c\n",
    "\n",
    "def emote(doc, n=5):\n",
    "    coord = sympathize(doc)\n",
    "    #     print(coord)\n",
    "    distances = [(i, dist(coord, (row[\"Sentiment score\"], row[\"Neut\"]))) for i, row in df.iterrows()]\n",
    "    nearest = sorted(distances, key=lambda tup: tup[1])\n",
    "    emojis = pd.DataFrame([(df[\"Char\"][i], distance) for i, distance in nearest])\n",
    "    return(\"\".join([emoji for emoji in emojis[:n][0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get emoji using sense2vec (huge download though)\n",
    "# def sim(char, doc):\n",
    "#     char_doc = make_spacy_doc(char)\n",
    "#     phrase_list = doc.s2v_phrases\n",
    "#     return(doc[0:-1]._.s2v_similarity(char_doc))\n",
    "\n",
    "# def emote(doc, n=5):\n",
    "#     distances = [(char, sim(char, doc)) for char in emoji_list]\n",
    "#     nearest = sorted(distances)\n",
    "#     return(nearest[:n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(tok, from_word=\"simple\", to_word=\"uncomplicated\", n=10):\n",
    "    tok_doc = make_spacy_doc(tok)\n",
    "    if tok_doc.vector is None:\n",
    "        return(\"something I don't know about\")\n",
    "    vec = tok_doc.vector - make_spacy_doc(from_word).vector #+ make_spacy_doc(to_word).vector\n",
    "#     vec = tok_doc.vector\n",
    "    vec_ids = nlp.vocab.vectors.most_similar(vec.reshape(1,vec.shape[0]), n=n)\n",
    "    new_toks = [nlp.vocab.strings[vec] for i, vec in enumerate(vec_ids[0][0])]\n",
    "    return(new_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crappy_sort(doc, memory, n=5):\n",
    "    if not doc._.phrases:\n",
    "        return \"...\"\n",
    "    thoughts = []\n",
    "    for p in doc._.phrases: \n",
    "        if p.text not in str(memory).lower():\n",
    "            for ent in doc.ents:\n",
    "                if ent.text.lower() in p.text:\n",
    "                    if ent.label_ == \"PERSON\" or ent.label_ == \"NORP\" or ent.label_ == \"ORG\":\n",
    "                        thoughts.append(f\"Who is {ent.text}?\")\n",
    "                    elif ent.label_ == \"GPE\" or ent.label_ == \"FAC\" or ent.label_ == \"LOC\": \n",
    "                        thoughts.append(f\"Where is {ent.text}?\")\n",
    "                    elif ent.label_ == \"DATE\" or ent.label_ == \"TIME\": \n",
    "                        thoughts.append(f\"When is {ent.text}?\")\n",
    "                    elif ent.label_ == \"PERCENT\" or ent.label_ == \"MONEY\"or ent.label_ == \"QUANTITY\": \n",
    "                        thoughts.append(f\"How much is {ent.text}?\")                \n",
    "                    else:\n",
    "                        thoughts.append(f\"What is {ent.text}? {ent.label_.capitalize()}?\")\n",
    "            new_toks = translate(p.text)\n",
    "            for tok in new_toks:\n",
    "                if tok not in memory:\n",
    "                    thoughts.append(f\"{p.text}... {tok}?...\")\n",
    "    return(\" \".join(thoughts[:n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def respond(stimulus, memory):\n",
    "    doc = make_spacy_doc(stimulus)\n",
    "    emoji = emote(doc, 1)\n",
    "    query = crappy_sort(doc, memory, 3)\n",
    "    return(f\"\\n----  {emoji} {query}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record(memory, outdir='output'):\n",
    "    now = str(date.today()) + \".md\"\n",
    "    outpath = Path(outdir)/now\n",
    "    with open(outpath, 'a') as f:\n",
    "        print(f'## {datetime.now()}', file=f)\n",
    "        print(' '.join(memory), file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"----  ðŸ˜ƒ What's happening?\")\n",
    "stimulus = \"Hi\"\n",
    "memory = []\n",
    "while stimulus != \"\":\n",
    "    stimulus = input()\n",
    "    response = respond(stimulus, memory)\n",
    "    memory.append(f'{stimulus}{response}')\n",
    "    print(response)\n",
    "record(memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
